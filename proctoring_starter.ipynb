{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec5e4a96-0156-4113-993e-8cad5bd31d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip -q install --upgrade mediapipe opencv-python numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfdf33a-e9c4-4514-842c-9380938fd7fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded to: D:\\Scripts\\Python Scripts\\AI Interview Cheating Detector\\face_landmarker.task size: 3758596 bytes\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "url = \"https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task\"\n",
    "out = Path(\"face_landmarker.task\")\n",
    "\n",
    "urllib.request.urlretrieve(url, out)\n",
    "print(\"Downloaded to:\", out.resolve(), \"size:\", out.stat().st_size, \"bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0f3bbc-c738-4cfe-8b79-b5ee5ed2f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from pathlib import Path\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9df8144d-43b6-444e-8ec8-e848ca9eaea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Landmark drawing (fast & simple) ----------\n",
    "def draw_landmarks(frame_bgr, face_landmarks, step=6):\n",
    "    \"\"\"\n",
    "    Draw a subset of landmarks for speed.\n",
    "    step=6 means draw every 6th landmark.\n",
    "    \"\"\"\n",
    "    h, w = frame_bgr.shape[:2]\n",
    "    for i in range(0, len(face_landmarks), step):\n",
    "        lm = face_landmarks[i]\n",
    "        x, y = int(lm.x * w), int(lm.y * h)\n",
    "        cv2.circle(frame_bgr, (x, y), 1, (0, 255, 0), -1)\n",
    "\n",
    "# ---------- Eye Aspect Ratio (EAR) helpers ----------\n",
    "def _pt(lm, w, h):\n",
    "    return np.array([lm.x * w, lm.y * h], dtype=np.float32)\n",
    "\n",
    "def eye_ear(lms, idx, w, h):\n",
    "    \"\"\"\n",
    "    EAR = (||p2-p6|| + ||p3-p5||) / (2*||p1-p4||)\n",
    "    idx: 6 landmark indices around the eye [p1,p2,p3,p4,p5,p6]\n",
    "    \"\"\"\n",
    "    p1, p2, p3, p4, p5, p6 = [_pt(lms[i], w, h) for i in idx]\n",
    "    v1 = np.linalg.norm(p2 - p6)\n",
    "    v2 = np.linalg.norm(p3 - p5)\n",
    "    hdist = np.linalg.norm(p1 - p4)\n",
    "    if hdist < 1e-6:\n",
    "        return 0.0\n",
    "    return float((v1 + v2) / (2.0 * hdist))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbd1cc8d-ce04-4144-9eb1-80b5114f4083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FaceLandmarker created\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"face_landmarker.task\"\n",
    "if not Path(MODEL_PATH).exists():\n",
    "    raise FileNotFoundError(f\"Model file not found: {MODEL_PATH}. Run the download cell first.\")\n",
    "\n",
    "latest_result = {\"res\": None}\n",
    "\n",
    "def _callback(result: vision.FaceLandmarkerResult, output_image: mp.Image, timestamp_ms: int):\n",
    "    latest_result[\"res\"] = (result, timestamp_ms)\n",
    "\n",
    "base_options = python.BaseOptions(model_asset_path=MODEL_PATH)\n",
    "\n",
    "options = vision.FaceLandmarkerOptions(\n",
    "    base_options=base_options,\n",
    "    running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "    num_faces=1,\n",
    "    output_face_blendshapes=False,\n",
    "    output_facial_transformation_matrixes=False,\n",
    "    result_callback=_callback\n",
    ")\n",
    "\n",
    "landmarker = vision.FaceLandmarker.create_from_options(options)\n",
    "print(\"FaceLandmarker created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50ccb79c-b2e1-461c-aa39-e1948d74e0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto-stopping after 25.0 seconds ✅\n",
      "Clean shutdown\n"
     ]
    }
   ],
   "source": [
    "# ------------------- CONFIG -------------------\n",
    "MAX_RUNTIME_SEC = 25.0\n",
    "\n",
    "# Face disappearance timer\n",
    "MISSING_THRESHOLD_SEC = 2.0\n",
    "missing_start = None\n",
    "max_missing = 0.0\n",
    "\n",
    "# Eye closure detection (EAR)\n",
    "LEFT_EYE_EAR_IDX  = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE_EAR_IDX = [263, 387, 385, 362, 380, 373]\n",
    "\n",
    "EAR_CLOSED_THR = 0.18        # tune per camera/face\n",
    "EYE_CLOSED_MIN_SEC = 0.25    # persistence to avoid blink false positives\n",
    "eye_closed_start = {\"L\": None, \"R\": None}\n",
    "\n",
    "# \"Looking away\" proxy thresholds\n",
    "DX_THR = 0.03   # left/right\n",
    "DY_THR = 0.05   # down\n",
    "\n",
    "# ------------------- RUN -------------------\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    landmarker.close()\n",
    "    raise RuntimeError(\"Could not open webcam.\")\n",
    "\n",
    "t0 = cv2.getTickCount()\n",
    "freq = cv2.getTickFrequency()\n",
    "start_time = time.time()\n",
    "\n",
    "def persistent_closed(is_closed, key, now):\n",
    "    if is_closed:\n",
    "        if eye_closed_start[key] is None:\n",
    "            eye_closed_start[key] = now\n",
    "        return (now - eye_closed_start[key]) >= EYE_CLOSED_MIN_SEC\n",
    "    else:\n",
    "        eye_closed_start[key] = None\n",
    "        return False\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Auto-stop after MAX_RUNTIME_SEC\n",
    "        if time.time() - start_time >= MAX_RUNTIME_SEC:\n",
    "            print(f\"Auto-stopping after {MAX_RUNTIME_SEC} seconds ✅\")\n",
    "            break\n",
    "\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        # timestamp in ms (monotonic-ish)\n",
    "        t = cv2.getTickCount()\n",
    "        timestamp_ms = int(((t - t0) / freq) * 1000)\n",
    "\n",
    "        # Convert OpenCV BGR -> RGB and wrap as mp.Image\n",
    "        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)\n",
    "\n",
    "        # Async detect (results come via callback)\n",
    "        landmarker.detect_async(mp_image, timestamp_ms)\n",
    "\n",
    "        # Defaults\n",
    "        face_detected = False\n",
    "        status = \"NO FACE\"\n",
    "        color = (0, 0, 255)\n",
    "\n",
    "        # Read latest result (may lag by a frame)\n",
    "        res_pack = latest_result[\"res\"]\n",
    "        if res_pack is not None:\n",
    "            result, _ts = res_pack\n",
    "            if result.face_landmarks and len(result.face_landmarks) > 0:\n",
    "                face_detected = True\n",
    "                status = \"FACE\"\n",
    "                color = (0, 255, 0)\n",
    "\n",
    "                # Landmarks for first face\n",
    "                lms = result.face_landmarks[0]\n",
    "                draw_landmarks(frame, lms, step=6)\n",
    "\n",
    "                # --- Looking-away proxy (dx/dy) ---\n",
    "                try:\n",
    "                    nose = lms[1]\n",
    "                    left_eye = lms[133]\n",
    "                    right_eye = lms[362]\n",
    "\n",
    "                    eye_mid_x = (left_eye.x + right_eye.x) / 2.0\n",
    "                    eye_mid_y = (left_eye.y + right_eye.y) / 2.0\n",
    "\n",
    "                    dx = nose.x - eye_mid_x\n",
    "                    dy = nose.y - eye_mid_y\n",
    "\n",
    "                    looking_away = (abs(dx) > DX_THR) or (dy > DY_THR)\n",
    "                    if looking_away:\n",
    "                        status = \"LOOKING AWAY (proxy)\"\n",
    "                        color = (0, 0, 255)\n",
    "                    else:\n",
    "                        status = \"LOOKING AT SCREEN (proxy)\"\n",
    "                        color = (0, 255, 0)\n",
    "\n",
    "                    cv2.putText(frame, f\"dx:{dx:.3f} dy:{dy:.3f}\", (10, 30),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "                # --- Eye closure / wink detection (EAR) ---\n",
    "                try:\n",
    "                    now = time.time()\n",
    "                    left_ear = eye_ear(lms, LEFT_EYE_EAR_IDX, w, h)\n",
    "                    right_ear = eye_ear(lms, RIGHT_EYE_EAR_IDX, w, h)\n",
    "\n",
    "                    left_closed = persistent_closed(left_ear < EAR_CLOSED_THR, \"L\", now)\n",
    "                    right_closed = persistent_closed(right_ear < EAR_CLOSED_THR, \"R\", now)\n",
    "\n",
    "                    eye_state = \"EYES OPEN\"\n",
    "                    eye_color = (0, 255, 0)\n",
    "\n",
    "                    if left_closed and right_closed:\n",
    "                        eye_state = \"BOTH EYES CLOSED\"\n",
    "                        eye_color = (0, 0, 255)\n",
    "                    elif left_closed and not right_closed:\n",
    "                        eye_state = \"LEFT EYE CLOSED (WINK)\"\n",
    "                        eye_color = (0, 165, 255)\n",
    "                    elif right_closed and not left_closed:\n",
    "                        eye_state = \"RIGHT EYE CLOSED (WINK)\"\n",
    "                        eye_color = (0, 165, 255)\n",
    "\n",
    "                    cv2.putText(frame, f\"L_EAR:{left_ear:.3f} R_EAR:{right_ear:.3f}\",\n",
    "                                (10, 95), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "                    cv2.putText(frame, eye_state,\n",
    "                                (10, 125), cv2.FONT_HERSHEY_SIMPLEX, 0.8, eye_color, 2)\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # --- Face disappearance timer ---\n",
    "        now = time.time()\n",
    "\n",
    "        if face_detected:\n",
    "            missing_start = None\n",
    "        else:\n",
    "            if missing_start is None:\n",
    "                missing_start = now\n",
    "\n",
    "        missing_duration = 0.0 if missing_start is None else (now - missing_start)\n",
    "        max_missing = max(max_missing, missing_duration)\n",
    "\n",
    "        if missing_duration >= MISSING_THRESHOLD_SEC:\n",
    "            status = f\"FACE MISSING > {MISSING_THRESHOLD_SEC:.1f}s\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # --- Overlay text ---\n",
    "        cv2.putText(frame, status, (10, 65),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)\n",
    "\n",
    "        cv2.putText(frame, f\"Missing: {missing_duration:.2f}s (max {max_missing:.2f}s)\",\n",
    "                    (10, 155), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "        remaining = max(0.0, MAX_RUNTIME_SEC - (time.time() - start_time))\n",
    "        cv2.putText(frame, f\"Auto-stop in: {remaining:.1f}s\",\n",
    "                    (10, 185), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "\n",
    "        cv2.imshow(\"MediaPipe Tasks - Starter (Face + Missing + Eyes)\", frame)\n",
    "\n",
    "        # Press q to stop early\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    landmarker.close()\n",
    "    print(\"Clean shutdown\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e450338-a8b5-48ff-b069-a5dd53831676",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
